{
  "Initial Steps": {
    "prefix": "steps",
    "body": [
      "// 1. create a prompt template",
      "$1",
      "// 2. choose an LLM",
      "$2",
      "// 3. parse the response",
      "$3",
      "// 4. runnable sequence (LCEL)",
      "$4",
      "// 5. invoke the chain",
      "$5",
      ""
    ],
    "description": "Starter pseudocode"
  },
  "You are a helpful assistant": {
    "prefix": ["helpfulassistant"],
    "body": [
      "`You are a helpful assistant.",
      "Answer the user's question to the best of your ability.`"
    ],
    "description": "You are a helpful assistant"
  },
  "Here are some documents": {
    "prefix": ["rag", "somedocuments", "herearesomedocuments"],
    "body": [
      "SystemMessagePromptTemplate.fromTemplate(`",
      "\tHere are some documents to help you answer the question.",
      "\tDon't use your pre-trained knowledge to answer the question.",
      "\tAlways include a full link to the meetup.",
      "\tIf the answer isn't included in the documents, say you don't know.",
      "",
      "\tDocuments:",
      "\t{documents}",
      "`)"
    ],
    "description": "You are a helpful assistant"
  },
  "Retrieval Query": {
    "prefix": ["retrievalQuery"],
    "body": [
      "retrievalQuery: `",
      "\tRETURN",
      "\t\t\tnode.description AS text, score,",
      "\t\t\tnode {",
      "\t\t\t\t.time, .title,",
      "\t\t\t\turl: 'https://athens.cityjsconf.org/'+ node.url,",
      "\t\t\t\tspeaker: [",
      "\t\t\t\t\t(node)-[:GIVEN_BY]->(s) |",
      "\t\t\t\t\ts { .name, .company, .x_handle, .bio }",
      "\t\t\t\t][0],",
      "\t\t\t\troom: [ (node)-[:IN_ROOM]->(r) | r.name ][0],",
      "\t\t\t\ttags: [ (node)-[:HAS_TAG]->(t) | t.name ]",
      "\t\t\t} AS metadata",
    ],
    "description": "Retrieve extra information as part of the document"
  },
  "Embeddings Model": {
    "prefix": ["constembeddings", "openaiembeddings"],
    "body": [
      "const embeddings = new OpenAIEmbeddings({",
        "\topenAiApiKey: process.env.OPENAI_API_KEY,",
      "});",
    ]
  },
  "Ollama Embeddings model": {
    "prefix": ["ollamaembeddings"],
    "body": [
      "const embeddings = new OllamaEmbeddings({",
        "\tmodel: 'nomic-embed-text',",
      "});",
    ]
  },
  "Create Vector Store": {
    "prefix": ["vectorstore"],
    "body": [
      "// Create vector store",
      "\tconst store = await Neo4jVectorStore.fromExistingGraph(embeddings, {",
      "\t\turl: process.env.NEO4J_URI,",
      "\t\tusername: process.env.NEO4J_USERNAME,",
      "\t\tpassword: process.env.NEO4J_PASSWORD,",
      "\t\tnodeLabel: \"Talk\",",
      "\t\ttextNodeProperties: [\"title\", \"description\"],",
      "\t\tindexName: \"talk_embeddings_openai\",",
      "\t\tembeddingNodeProperty: \"embedding\",",
      "\t\tretrievalQuery: `",
      "RETURN node.description AS text, score,",
      "node {",
      "\t\t.time, .title,",
      "\t\turl: 'https://athens.cityjsconf.org/'+ node.url,",
      "\t\tspeaker: [",
      "\t\t(node)-[:GIVEN_BY]->(s) |",
      "\t\ts { .name, .company, .x_handle, .bio }",
      "\t\t][0],",
      "\t\troom: [ (node)-[:IN_ROOM]->(r) | r.name ][0],",
      "\t\ttags: [ (node)-[:HAS_TAG]->(t) | t.name ]",
      "",
      "} AS metadata",
      "`,",
      "\t});"
    ],
    "description": "Create a vector store"
  },
  "LLM": {
    "prefix": ["constllm"],
    "body": "const llm = new ChatOpenAI($1)",
    "description": "Create an LLM"
  },
  "OpenAI API KEY": {
    "prefix": ["openaiapikey"],
    "body": "process.env.OPENAI_API_KEY",
    "description": "OpenAI API Key from process.env"

  },
  "Output Parser": {
    "prefix": ["constparser"],
    "body": "const parser = new StringOutputParser()",
    "description": "Parse a string"
  },
  "Output": {
    "prefix": ["constoutput"],
    "body": "const output = await chain.invoke($1)",
    "description": "Parse a string"
  },
  "Return": {
    "prefix": ["returnoutput"],
    "body": "return output",
    "description": "return output"
  }
}
